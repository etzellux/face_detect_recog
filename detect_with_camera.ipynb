{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41ed717f-96b6-4a2f-8bc1-8361e0217e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from scipy.spatial.distance import cosine\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16f39e6b-ea03-40f0-9e3d-4e80af831af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution() #optimization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a04c2a0-1ddd-4069-91e0-7ac7bb5529b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def highlight_faces(image, faces):\n",
    "  \n",
    "    for face in faces:\n",
    "        x, y, width, height = face['box']\n",
    "        cv2.rectangle(image,(x,y),(x + width, y + height),color=(0,0,255),thickness=4)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "478babd0-5bcf-4454-be15-0478f0e748ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_res(cap, width, height):\n",
    "    cap.set(3, width)\n",
    "    cap.set(4, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77074b7e-c664-4eaa-b389-48a5be0b6674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_from_image(image, face_infos, required_size=(224, 224)):\n",
    "  # load image and detect faces\n",
    "  \n",
    "    face_images = []\n",
    "\n",
    "    for face in face_infos:\n",
    "        # extract the bounding box from the requested face\n",
    "        x1, y1, width, height = face['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "        # extract the face\n",
    "        face_boundary = image[y1:y2, x1:x2]\n",
    "\n",
    "        # resize pixels to the model size\n",
    "        face_image = Image.fromarray(face_boundary)\n",
    "        face_image = face_image.resize(required_size)\n",
    "        face_array = asarray(face_image)\n",
    "        face_images.append(face_array)\n",
    "\n",
    "    return face_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98e72e4b-ed00-4521-bf37-0fdada574be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGFace(model='resnet50',\n",
    "      include_top=False,\n",
    "      input_shape=(224, 224, 3),\n",
    "      pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb5431c3-bfd0-4b36-84a0-54d9c2e1d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_mapping(faces, target_face):\n",
    "    faces = np.append(faces, target_face, axis=0)\n",
    "    samples = asarray(faces, 'float32')\n",
    "\n",
    "  # prepare the data for the model\n",
    "    samples = preprocess_input(samples, version=2)\n",
    "\n",
    "  # perform prediction\n",
    "    return model.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3c0fa2f-5075-44a8-9228-f9d3b4c9a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7972b3d3-343b-43c9-bcff-1f0e50643719",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "change_res(cap, 200, 130)\n",
    "detector = MTCNN()\n",
    "\n",
    "target = cv2.imread(\"images/myphoto1.jpeg\") # read students face\n",
    "target = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)\n",
    "target_face_info = detector.detect_faces(target) # get face boundaries\n",
    "\n",
    "target_face = np.array(extract_face_from_image(target, target_face_info)) # extract face and append to array\n",
    "\n",
    "face_matched = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aef346eb-0c98-4420-94d8-b8db7acc17a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read() # read from camera\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #detect faces\n",
    "    face_infos = detector.detect_faces(frame_rgb) \n",
    "    face_infos = np.array(face_infos)\n",
    "    \n",
    "    if len(face_infos) > 0 :\n",
    "        face_id = 0\n",
    "        face_images = extract_face_from_image(frame_rgb, face_infos)\n",
    "        # TODO: flush faces except target in every loop                   \n",
    "        #faces = np.append(face_infos, target_face, axis=0)\n",
    "        \n",
    "        face_vectors = get_face_mapping(face_images, target_face)\n",
    "         \n",
    "        face_count = face_vectors.shape[0]\n",
    "                                \n",
    "        for i in range(0, face_count):\n",
    "            for j in range(i, face_count):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if cosine(face_vectors[i], face_vectors[j]) <= threshold:\n",
    "                    face_id = i\n",
    "                    face_matched = True\n",
    "                \n",
    "        #if not face_matched:\n",
    "            #print(\"no face matched\")\n",
    "                                \n",
    "    #highlight_faces(frame, faces)\n",
    "    \n",
    "    for face in face_infos:\n",
    "        x, y, width, height = face['box']\n",
    "        cv2.rectangle(frame, (x,y), (x + width, y + height), color=(0,0,255), thickness=2)\n",
    "    try:    \n",
    "        if face_matched and face_count > 1:\n",
    "            x, y, width, height = face_infos[face_id]['box']\n",
    "            cv2.putText(frame, \"student matched\", (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, color=(0,255,0), thickness=2)\n",
    "            \n",
    "            if face_count > 2:\n",
    "                cv2.putText(frame, \"WARNING!\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, color=(255,0,255), thickness=2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    # press ESC to close window\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758b28b-1bed-4773-8661-84b5bea3e8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
